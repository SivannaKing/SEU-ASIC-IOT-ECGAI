{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT LIBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "import pandas as pd\n",
    "import os\n",
    "import collections\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Conv1D, BatchNormalization, MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from qkeras import *\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/wzx/ECGAI/EXP1/1D_CNN'\n",
    "\n",
    "dataset_path =  '/home/wzx/ECGAI/EXP1/Dataset/' # Training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLOT SETTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "plt.rcParams['lines.color'] = 'b'\n",
    "plt.rcParams['axes.grid'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_base(Unit, Kernel, Conv_Stride, Maxpool_Stride, input_tensor = None, wei = 4):\n",
    "    \n",
    "    input_shape = (None, 3)\n",
    "\n",
    "    ecg_input = input_tensor\n",
    "\n",
    "    bn_axis = 3\n",
    "\n",
    "    # nn_base\n",
    "    x = QConv1D(filters = Unit, kernel_size = Kernel, padding = 'same', strides = Conv_Stride, \n",
    "                kernel_quantizer=quantized_bits(wei,0,1), bias_quantizer=quantized_bits(wei,0,1),\n",
    "               data_format='channels_last')(ecg_input)\n",
    "    x = QActivation(\"quantized_relu(4,0)\")(x)\n",
    "    \n",
    "    # x = BatchNormalization()(x)\n",
    "    \n",
    "    x = MaxPooling1D(pool_size = 2, strides = Maxpool_Stride, padding = 'same', \n",
    "                     data_format='channels_last')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_layer(base_layer, dropout_rate = 0.1, ClassesNum = 17, wei = 4):\n",
    "    \n",
    "    # classifier layers\n",
    "    x = QConv1D(filters = 32, kernel_size = 10, padding = 'same', \n",
    "                kernel_quantizer=quantized_bits(wei,0,1), bias_quantizer=quantized_bits(wei,0,1),\n",
    "               name = 'classifier_layer_Conv1D1', data_format='channels_last')(base_layer)\n",
    "    x = QActivation(\"quantized_relu(4,0)\", name = 'QActivation_relu1')(x)\n",
    "    \n",
    "    x = QConv1D(filters = 128, kernel_size = 5, padding = 'same', \n",
    "                kernel_quantizer=quantized_bits(wei,0,1), bias_quantizer=quantized_bits(wei,0,1),\n",
    "               strides = 2, name = 'classifier_layer_Conv1D2', data_format='channels_last')(x)\n",
    "    x = QActivation(\"quantized_relu(4,0)\", name = 'QActivation_relu2')(x)\n",
    "    \n",
    "    x = MaxPooling1D(pool_size = 2, strides = 2, padding = 'same', \n",
    "                     name = 'classifier_layer_MaxPooling1D1', data_format='channels_last')(x)\n",
    "    \n",
    "    x = QConv1D(filters = 256, kernel_size = 15, padding = 'same', \n",
    "                kernel_quantizer=quantized_bits(wei,0,1), bias_quantizer=quantized_bits(wei,0,1),\n",
    "               name = 'classifier_layer_Conv1D3', data_format='channels_last')(x)\n",
    "    x = QActivation(\"quantized_relu(4,0)\", name = 'QActivation_relu3')(x)\n",
    "    \n",
    "    x = MaxPooling1D(pool_size = 2, strides = 2, padding = 'same', \n",
    "                     name = 'classifier_layer_MaxPooling1D2', data_format='channels_last')(x)\n",
    "    \n",
    "    x = QConv1D(filters = 512, kernel_size = 5, padding = 'same', \n",
    "                kernel_quantizer=quantized_bits(wei,0,1), bias_quantizer=quantized_bits(wei,0,1),\n",
    "               name = 'classifier_layer_Conv1D4', data_format='channels_last')(x)\n",
    "    x = QActivation(\"quantized_relu(4,0)\", name = 'QActivation_relu4')(x)\n",
    "    \n",
    "    x = QConv1D(filters = 128, kernel_size = 3, padding = 'same',\n",
    "                kernel_quantizer=quantized_bits(wei,0,1), bias_quantizer=quantized_bits(wei,0,1),\n",
    "               name = 'classifier_layer_Conv1D5', data_format='channels_last')(x)\n",
    "    x = QActivation(\"quantized_relu(4,0)\", name = 'QActivation_relu5')(x)\n",
    "    \n",
    "    \n",
    "    x = Flatten(name = 'classifier_layer_Flatten')(x)\n",
    "    \n",
    "    x = QDense(units = 512, \n",
    "               kernel_quantizer=quantized_bits(wei,0,1), bias_quantizer=quantized_bits(wei,0,1),\n",
    "               name = 'classifier_layer_Dense1')(x)\n",
    "    x = QActivation(\"quantized_relu(4,0)\", name = 'QActivation_relu6')(x)\n",
    "    \n",
    "    x = Dropout(rate = dropout_rate, name = 'classifier_layer_Dropout')(x)\n",
    "    \n",
    "    x = QDense(units = ClassesNum, \n",
    "               kernel_quantizer=quantized_bits(wei,0,1), bias_quantizer=quantized_bits(wei,0,1),\n",
    "               name = 'classifier_layer_Dense2')(x)\n",
    "    x = Activation(\"softmax\", name=\"softmax\")(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Variables\n",
    "\n",
    "classes = ['NSR', 'APB', 'AFL', 'AFIB', 'SVTA', 'WPW','PVC', 'Bigeminy', 'Trigeminy', \n",
    "           'VT', 'IVR', 'VFL', 'Fusion', 'LBBBB', 'RBBBB', 'SDHB', 'PR']\n",
    "ClassesNum = len(classes)\n",
    "\n",
    "X = list()\n",
    "y = list()\n",
    "\n",
    "for root, dirs, files in os.walk(dataset_path, topdown=False):\n",
    "    for name in files:\n",
    "        data_train = scio.loadmat(os.path.join(root, name))# 取出字典里的value\n",
    "        \n",
    "        # arr -> list\n",
    "        data_arr = data_train.get('val')\n",
    "        data_list = data_arr.tolist()\n",
    "        \n",
    "        # z-score normalization\n",
    "        sum = 0\n",
    "        max = 0\n",
    "        for i in range(len(data_list[0])):\n",
    "            sum = data_list[0][i] + sum\n",
    "        average = float(sum/len(data_list[0]))\n",
    "        total = 0\n",
    "        for value in data_list[0]:\n",
    "            total += (value - average) ** 2\n",
    "        stddev = math.sqrt(total/len(data_list))\n",
    "        data_list[0] = [(x-average)/stddev for x in data_list[0]]\n",
    "        \n",
    "        X.append(data_list[0]) # [[……]] -> [ ]\n",
    "        y.append(int(os.path.basename(root)[0:2]) - 1)  # name -> num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### START TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total num of training data :  1000\n",
      "X_train :  800\n",
      "X_test  :  200\n",
      "y_train :  Counter({0: 234, 3: 109, 6: 103, 13: 77, 1: 50, 14: 50, 7: 42, 16: 38, 5: 18, 2: 17, 12: 10, 4: 10, 8: 10, 15: 9, 10: 8, 11: 8, 9: 7})\n",
      "y_test  :  Counter({0: 49, 6: 30, 3: 26, 13: 26, 1: 16, 7: 13, 14: 12, 16: 7, 2: 3, 8: 3, 5: 3, 4: 3, 9: 3, 10: 2, 11: 2, 12: 1, 15: 1})\n",
      "shape of X_train :  (3600,)\n",
      "shape of y_train :  (800,)\n",
      "shape of X_test :  (200, 3600)\n",
      "shape of y_test :  (200,)\n"
     ]
    }
   ],
   "source": [
    "# list -> arr\n",
    "X=np.array(X)\n",
    "y=np.array(y)\n",
    "\n",
    "print(\"total num of training data : \", len(X))\n",
    "\n",
    "# get X_train, X_test, y_train, y_test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(\"X_train : \", len(X_train))\n",
    "print(\"X_test  : \", len(X_test))\n",
    "print(\"y_train : \", collections.Counter(y_train))\n",
    "print(\"y_test  : \", collections.Counter(y_test))\n",
    "print(\"shape of X_train : \", np.shape(X_train[0]))\n",
    "print(\"shape of y_train : \", np.shape(y_train))\n",
    "print(\"shape of X_test : \", np.shape(X_test))\n",
    "print(\"shape of y_test : \", np.shape(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUILD MODEL_SEQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wzx/anaconda3/envs/ecgai/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/wzx/anaconda3/envs/ecgai/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1200, 128)         6528      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1200, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 400, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 400, 32)           28704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 400, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 200, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 200, 32)           10272     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 100, 128)          20608     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 50, 256)           491776    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 25, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 25, 512)           655872    \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 25, 128)           196736    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1638912   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 17)                8721      \n",
      "=================================================================\n",
      "Total params: 3,058,769\n",
      "Trainable params: 3,058,449\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_all = Sequential()\n",
    "model_all.add(Conv1D(128, 50, padding = 'same', activation='relu', strides = 3,\n",
    "                     input_shape=(3600,1), data_format='channels_last'))\n",
    "model_all.add(BatchNormalization())\n",
    "model_all.add(MaxPooling1D(3, padding = 'same', data_format='channels_last'))\n",
    "\n",
    "model_all.add(Conv1D(32, 7, padding = 'same', activation='relu', strides = 1, data_format='channels_last'))\n",
    "model_all.add(BatchNormalization())\n",
    "model_all.add(MaxPooling1D(2, padding = 'same', data_format='channels_last'))\n",
    "\n",
    "model_all.add(Conv1D(32, 10, padding = 'same', activation='relu', strides = 1, data_format='channels_last'))\n",
    "model_all.add(Conv1D(128, 5, padding = 'same', activation='relu', strides = 2, data_format='channels_last'))\n",
    "model_all.add(MaxPooling1D(2,padding = 'same', data_format='channels_last'))\n",
    "\n",
    "model_all.add(Conv1D(256, 15, padding = 'same', activation='relu', strides = 1, data_format='channels_last'))\n",
    "model_all.add(MaxPooling1D(2, padding = 'same', data_format='channels_last')) \n",
    "\n",
    "model_all.add(Conv1D(512, 5, padding = 'same', activation='relu', strides = 1, data_format='channels_last'))\n",
    "model_all.add(Conv1D(128, 3, padding = 'same', activation='relu', strides = 1, data_format='channels_last'))\n",
    "model_all.add(Flatten(data_format='channels_last'))\n",
    "\n",
    "model_all.add(Dense(512, activation='relu'))\n",
    "model_all.add(Dropout(0.1))\n",
    "model_all.add(Dense(ClassesNum, activation='softmax'))\n",
    "\n",
    "print(model_all.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUILD MODEL_MOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3600, 1)           0         \n",
      "_________________________________________________________________\n",
      "q_conv1d_1 (QConv1D)         (None, 1200, 128)         6528      \n",
      "_________________________________________________________________\n",
      "q_activation_1 (QActivation) (None, 1200, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 400, 128)          0         \n",
      "_________________________________________________________________\n",
      "q_conv1d_2 (QConv1D)         (None, 400, 32)           28704     \n",
      "_________________________________________________________________\n",
      "q_activation_2 (QActivation) (None, 400, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 200, 32)           0         \n",
      "_________________________________________________________________\n",
      "classifier_layer_Conv1D1 (QC (None, 200, 32)           10272     \n",
      "_________________________________________________________________\n",
      "QActivation_relu1 (QActivati (None, 200, 32)           0         \n",
      "_________________________________________________________________\n",
      "classifier_layer_Conv1D2 (QC (None, 100, 128)          20608     \n",
      "_________________________________________________________________\n",
      "QActivation_relu2 (QActivati (None, 100, 128)          0         \n",
      "_________________________________________________________________\n",
      "classifier_layer_MaxPooling1 (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "classifier_layer_Conv1D3 (QC (None, 50, 256)           491776    \n",
      "_________________________________________________________________\n",
      "QActivation_relu3 (QActivati (None, 50, 256)           0         \n",
      "_________________________________________________________________\n",
      "classifier_layer_MaxPooling1 (None, 25, 256)           0         \n",
      "_________________________________________________________________\n",
      "classifier_layer_Conv1D4 (QC (None, 25, 512)           655872    \n",
      "_________________________________________________________________\n",
      "QActivation_relu4 (QActivati (None, 25, 512)           0         \n",
      "_________________________________________________________________\n",
      "classifier_layer_Conv1D5 (QC (None, 25, 128)           196736    \n",
      "_________________________________________________________________\n",
      "QActivation_relu5 (QActivati (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "classifier_layer_Flatten (Fl (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "classifier_layer_Dense1 (QDe (None, 512)               1638912   \n",
      "_________________________________________________________________\n",
      "QActivation_relu6 (QActivati (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "classifier_layer_Dropout (Dr (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "classifier_layer_Dense2 (QDe (None, 17)                8721      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 17)                0         \n",
      "=================================================================\n",
      "Total params: 3,058,129\n",
      "Trainable params: 3,058,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_ecg = Input(shape=(3600,1))\n",
    "x = nn_base(128, 50, Conv_Stride = 3, Maxpool_Stride = 3, input_tensor = input_ecg, wei = 4)\n",
    "x = nn_base(32, 7, Conv_Stride = 1, Maxpool_Stride = 2, input_tensor = x, wei = 4)\n",
    "output_ecg = classifier_layer(x, dropout_rate = 0.1, ClassesNum = 17, wei = 4)\n",
    "model_m = Model(input_ecg, output_ecg)\n",
    "print(model_m.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SETTING OPTIMIZERS & COMPILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 3600, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# setting optimizers & compile\n",
    "optimizers.Adam(lr = 0.01, beta_1 = 0.9, beta_2 = 0.999, epsilon = None, decay = 0.0, amsgrad = False)\n",
    "# model_all.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model_m.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# expand X_train dims\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_test = np.reshape(X_test, (np.shape(X_test)[0], np.shape(X_test)[1], 1))\n",
    "# Y : int -> binary (one-hot)\n",
    "y_train = to_categorical(y_train,num_classes = ClassesNum)\n",
    "y_test = to_categorical(y_test,num_classes = ClassesNum)\n",
    "\n",
    "display(np.shape(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wzx/anaconda3/envs/ecgai/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/wzx/anaconda3/envs/ecgai/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 2.4239 - accuracy: 0.2725\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 2.2150 - accuracy: 0.2925\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 1.9253 - accuracy: 0.3562\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 1.5319 - accuracy: 0.4762\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 1.1804 - accuracy: 0.5913\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.9434 - accuracy: 0.6925\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.6967 - accuracy: 0.7588\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.5064 - accuracy: 0.8363\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.4802 - accuracy: 0.8363\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.3497 - accuracy: 0.8725\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2656 - accuracy: 0.9137\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.2014 - accuracy: 0.9413\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.1971 - accuracy: 0.9350\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.3023 - accuracy: 0.8975\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.1118 - accuracy: 0.9663\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.1158 - accuracy: 0.9675\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.0578 - accuracy: 0.9837\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.0610 - accuracy: 0.9875\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.0333 - accuracy: 0.9950\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.0156 - accuracy: 0.9975\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.0320 - accuracy: 0.9925\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.0462 - accuracy: 0.9887\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.0172 - accuracy: 0.9962\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.0333 - accuracy: 0.9925\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.0704 - accuracy: 0.9800\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.0574 - accuracy: 0.9800\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.0206 - accuracy: 0.9962\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 9.3700e-04 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 9.0634e-04 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 7.9544e-04 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 7.4101e-04 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 7.0951e-04 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 5.9163e-04 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 5.6923e-04 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 5.4623e-04 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 4.8653e-04 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 4.8973e-04 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 4.2572e-04 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 3.9373e-04 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 4.0448e-04 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 3.4896e-04 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 3.3086e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "# history = model_all.fit(X_train, y_train, batch_size = BATCH_SIZE, epochs = EPOCHS)\n",
    "history = model_m.fit(X_train, y_train, batch_size = BATCH_SIZE, epochs = EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRINT ACC&LOSS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy'])\n",
      "[2.423948259353638, 2.215043296813965, 1.9253125262260438, 1.5318781447410583, 1.180393726825714, 0.9433964276313782, 0.6967418426275254, 0.5064331483840943, 0.48016825556755066, 0.34969711549580096, 0.2656042581796646, 0.2014003974944353, 0.19710624061524867, 0.302267953902483, 0.1117593902349472, 0.11575125047937035, 0.05781869908794761, 0.06102100647985935, 0.03328856946900487, 0.015618561236187815, 0.03198358120396733, 0.04618866348639131, 0.017239013961516322, 0.033333075982518494, 0.07037743951193988, 0.057434636540710925, 0.020576246441341938, 0.008143487367779017, 0.0031226170109584926, 0.002228592066094279, 0.0017335997463669628, 0.001533189929323271, 0.0013760470424313098, 0.001116918483749032, 0.001083171854261309, 0.0009369975561276078, 0.0009063365263864399, 0.0007954413257539272, 0.0007410144410096109, 0.0007095119880978018, 0.0005916337994858622, 0.0005692262752563693, 0.0005462282162625343, 0.00048652597120963037, 0.0004897311140666716, 0.0004257167910691351, 0.0003937300157849677, 0.00040447931649396197, 0.00034895510820206257, 0.0003308575847768225]\n",
      "[0.2725, 0.2925, 0.35625, 0.47625, 0.59125, 0.6925, 0.75875, 0.83625, 0.83625, 0.8725, 0.91375, 0.94125, 0.935, 0.8975, 0.96625, 0.9675, 0.98375, 0.9875, 0.995, 0.9975, 0.9925, 0.98875, 0.99625, 0.9925, 0.98, 0.98, 0.99625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "print(history.history['loss'])\n",
    "print(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRINT PLOT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'acc')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# put into df\n",
    "record_arr = np.array([history.history['loss'][0], history.history['accuracy'][0]])\n",
    "for i in range(1, EPOCHS):\n",
    "    new_row = np.array([history.history['loss'][i], history.history['accuracy'][i]])\n",
    "    record_arr = np.row_stack((record_arr, new_row))\n",
    "    \n",
    "record_df = pd.DataFrame(record_arr, columns=[\"loss\", \"acc\"])\n",
    "\n",
    "#print curve\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(np.arange(0, EPOCHS), record_df[\"loss\"], 'r')\n",
    "plt.title('loss')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(np.arange(0, EPOCHS), record_df[\"acc\"], 'r')\n",
    "plt.title('acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAL ACC LOSS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 1s 3ms/step\n",
      "score of val :  0.572066293247044\n",
      "acc of val :  0.9150000214576721\n"
     ]
    }
   ],
   "source": [
    "# val_loss_acc = model_all.evaluate(X_test, y_test, batch_size=100)\n",
    "val_loss_acc = model_m.evaluate(X_test, y_test, batch_size = 16)\n",
    "print(\"score of val : \", val_loss_acc[0])\n",
    "print(\"acc of val : \", val_loss_acc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WEIGHTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... quantizing model\n",
      "q_conv1d_1 0\n",
      "q_conv1d_1 1\n",
      "q_conv1d_2 0\n",
      "q_conv1d_2 1\n",
      "classifier_layer_Conv1D1 0\n",
      "classifier_layer_Conv1D1 1\n",
      "classifier_layer_Conv1D2 0\n",
      "classifier_layer_Conv1D2 1\n",
      "classifier_layer_Conv1D3 0\n",
      "classifier_layer_Conv1D3 1\n",
      "classifier_layer_Conv1D4 0\n",
      "classifier_layer_Conv1D4 1\n",
      "classifier_layer_Conv1D5 0\n",
      "classifier_layer_Conv1D5 1\n",
      "classifier_layer_Dense1 0\n",
      "classifier_layer_Dense1 1\n",
      "classifier_layer_Dense2 0\n",
      "classifier_layer_Dense2 1\n",
      "3058129\n",
      "q_conv1d_1 0 (50, 1, 128)\n",
      "q_conv1d_1 1 (128,)\n",
      "q_conv1d_2 0 (7, 128, 32)\n",
      "q_conv1d_2 1 (32,)\n",
      "classifier_layer_Conv1D1 0 (10, 32, 32)\n",
      "classifier_layer_Conv1D1 1 (32,)\n",
      "classifier_layer_Conv1D2 0 (5, 32, 128)\n",
      "classifier_layer_Conv1D2 1 (128,)\n",
      "classifier_layer_Conv1D3 0 (15, 128, 256)\n",
      "classifier_layer_Conv1D3 1 (256,)\n",
      "classifier_layer_Conv1D4 0 (5, 256, 512)\n",
      "classifier_layer_Conv1D4 1 (512,)\n",
      "classifier_layer_Conv1D5 0 (3, 512, 128)\n",
      "classifier_layer_Conv1D5 1 (128,)\n",
      "classifier_layer_Dense1 0 (3200, 512)\n",
      "classifier_layer_Dense1 1 (512,)\n",
      "classifier_layer_Dense2 0 (512, 17)\n",
      "classifier_layer_Dense2 1 (17,)\n",
      "[array([[[-0.375, -0.25 , -0.125, ..., -0.125, -0.125,  0.   ]],\n",
      "\n",
      "       [[-0.125, -0.375,  0.125, ..., -0.125, -0.125,  0.   ]],\n",
      "\n",
      "       [[ 0.125,  0.   ,  0.125, ..., -0.25 ,  0.   ,  0.125]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.375,  0.25 ,  0.   , ...,  0.   ,  0.125, -0.375]],\n",
      "\n",
      "       [[ 0.375,  0.125,  0.125, ..., -0.125,  0.375,  0.125]],\n",
      "\n",
      "       [[ 0.125,  0.   ,  0.125, ...,  0.125,  0.25 , -0.125]]],\n",
      "      dtype=float32), array([ 0.   ,  0.   ,  0.   , -0.125,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   , -0.125,  0.   , -0.125, -0.125,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   , -0.125,  0.   ,  0.   , -0.125,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   , -0.125,  0.   , -0.125,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   , -0.125,\n",
      "       -0.125,  0.   , -0.125,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   , -0.125,  0.   ,\n",
      "       -0.125,  0.   , -0.125, -0.125, -0.125,  0.   ,  0.   ,  0.   ,\n",
      "       -0.125,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   , -0.125,\n",
      "       -0.125,  0.   , -0.125,  0.   , -0.125,  0.   ,  0.   ,  0.   ,\n",
      "        0.   , -0.125, -0.125, -0.125,  0.   , -0.125,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   , -0.125,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   , -0.125, -0.125,  0.   ,  0.   ,  0.   ,  0.   ],\n",
      "      dtype=float32), array([[[ 0.   , -0.125,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [-0.125,  0.   , -0.125, ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   , -0.125],\n",
      "        ...,\n",
      "        [ 0.   ,  0.   ,  0.125, ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.125, ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   , -0.125,  0.   , ...,  0.   ,  0.   ,  0.   ]],\n",
      "\n",
      "       [[ 0.   ,  0.   ,  0.125, ..., -0.125,  0.   ,  0.125],\n",
      "        [-0.125,  0.125,  0.   , ..., -0.125, -0.125,  0.125],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        ...,\n",
      "        [-0.125,  0.   ,  0.125, ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   , -0.125,  0.   , ..., -0.125,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   , -0.125]],\n",
      "\n",
      "       [[ 0.   ,  0.   ,  0.125, ...,  0.   ,  0.125,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.125,  0.   ,  0.125],\n",
      "        [ 0.   ,  0.   ,  0.125, ...,  0.   ,  0.   ,  0.   ],\n",
      "        ...,\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.125, -0.125,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.125, ...,  0.   , -0.125,  0.   ],\n",
      "        [-0.125,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.125,  0.   ,  0.   , ...,  0.   ,  0.125,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ..., -0.125,  0.   ,  0.   ],\n",
      "        [-0.125,  0.   ,  0.   , ...,  0.   ,  0.125,  0.   ],\n",
      "        ...,\n",
      "        [ 0.   , -0.125, -0.125, ...,  0.   , -0.125,  0.125],\n",
      "        [-0.125, -0.125,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.125,  0.   ,  0.   , ...,  0.   ,  0.125,  0.   ]],\n",
      "\n",
      "       [[ 0.   ,  0.   ,  0.125, ..., -0.125,  0.125,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.125,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        ...,\n",
      "        [ 0.   ,  0.   , -0.125, ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.125],\n",
      "        [ 0.   ,  0.   ,  0.125, ...,  0.   ,  0.   ,  0.   ]],\n",
      "\n",
      "       [[ 0.   ,  0.   ,  0.   , ..., -0.125, -0.125,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.125,  0.   ,  0.125],\n",
      "        [ 0.125,  0.125, -0.125, ...,  0.   ,  0.   ,  0.   ],\n",
      "        ...,\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.25 ,  0.   ]]],\n",
      "      dtype=float32), array([ 0.   ,  0.   , -0.125,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   , -0.125,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   , -0.125,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
      "      dtype=float32), array([[[-0.125,  0.   , -0.125, ...,  0.   ,  0.   , -0.125],\n",
      "        [-0.125,  0.125,  0.   , ...,  0.   ,  0.   , -0.125],\n",
      "        [ 0.   ,  0.25 ,  0.   , ...,  0.   ,  0.125,  0.   ],\n",
      "        ...,\n",
      "        [ 0.   ,  0.125,  0.   , ...,  0.   ,  0.   ,  0.125],\n",
      "        [ 0.   ,  0.   ,  0.125, ...,  0.   ,  0.125,  0.   ],\n",
      "        [ 0.125,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.125]],\n",
      "\n",
      "       [[-0.125, -0.125,  0.   , ...,  0.   ,  0.125, -0.125],\n",
      "        [ 0.125,  0.   , -0.125, ...,  0.   ,  0.125,  0.125],\n",
      "        [-0.125,  0.125,  0.   , ...,  0.125,  0.   ,  0.   ],\n",
      "        ...,\n",
      "        [ 0.125,  0.   ,  0.125, ..., -0.125,  0.125,  0.   ],\n",
      "        [ 0.125,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   , -0.25 ,  0.125, ...,  0.   ,  0.125,  0.   ]],\n",
      "\n",
      "       [[ 0.   ,  0.125,  0.   , ..., -0.125,  0.   , -0.125],\n",
      "        [ 0.   , -0.125, -0.125, ...,  0.   ,  0.   ,  0.125],\n",
      "        [ 0.125,  0.125,  0.   , ...,  0.   ,  0.   , -0.125],\n",
      "        ...,\n",
      "        [ 0.125,  0.   ,  0.125, ..., -0.125, -0.125,  0.   ],\n",
      "        [-0.125,  0.125,  0.125, ...,  0.   ,  0.   ,  0.125],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.125,  0.   , -0.125]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.125,  0.   ,  0.125, ...,  0.125, -0.25 ,  0.125],\n",
      "        [-0.125,  0.125,  0.   , ...,  0.125,  0.125,  0.   ],\n",
      "        [-0.125,  0.   , -0.125, ...,  0.   , -0.125,  0.125],\n",
      "        ...,\n",
      "        [ 0.125,  0.   , -0.25 , ..., -0.25 , -0.125,  0.   ],\n",
      "        [-0.125,  0.   ,  0.125, ...,  0.125, -0.125,  0.   ],\n",
      "        [ 0.   ,  0.125,  0.   , ..., -0.125,  0.   ,  0.   ]],\n",
      "\n",
      "       [[ 0.   ,  0.125,  0.125, ...,  0.   , -0.125,  0.125],\n",
      "        [-0.125,  0.125,  0.   , ...,  0.   ,  0.125, -0.125],\n",
      "        [ 0.125,  0.125, -0.125, ...,  0.125,  0.   , -0.125],\n",
      "        ...,\n",
      "        [-0.125,  0.125,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.125, ...,  0.125,  0.   ,  0.   ],\n",
      "        [ 0.   , -0.125, -0.125, ...,  0.   ,  0.   , -0.125]],\n",
      "\n",
      "       [[ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.125, ...,  0.125,  0.   , -0.125],\n",
      "        [ 0.   ,  0.   ,  0.125, ..., -0.125,  0.   ,  0.   ],\n",
      "        ...,\n",
      "        [ 0.125,  0.125,  0.125, ..., -0.25 ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.125,  0.125,  0.   ],\n",
      "        [-0.125,  0.   ,  0.   , ...,  0.   ,  0.   , -0.125]]],\n",
      "      dtype=float32), array([0.   , 0.   , 0.125, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   ], dtype=float32), array([[[ 0.   , -0.125,  0.125, ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.125,  0.125, -0.125, ..., -0.125,  0.   , -0.125],\n",
      "        [ 0.25 , -0.125,  0.   , ...,  0.125,  0.   ,  0.   ],\n",
      "        ...,\n",
      "        [ 0.   , -0.125,  0.   , ...,  0.125, -0.125, -0.125],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   , -0.25 ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.125, ...,  0.   ,  0.   ,  0.125]],\n",
      "\n",
      "       [[ 0.25 ,  0.125,  0.125, ...,  0.125,  0.   ,  0.   ],\n",
      "        [-0.25 ,  0.125,  0.   , ..., -0.125, -0.125,  0.   ],\n",
      "        [-0.125,  0.125, -0.125, ...,  0.   , -0.125, -0.125],\n",
      "        ...,\n",
      "        [-0.125, -0.125,  0.   , ..., -0.25 , -0.125, -0.125],\n",
      "        [ 0.125,  0.   , -0.125, ...,  0.   , -0.125, -0.125],\n",
      "        [-0.125, -0.125,  0.   , ...,  0.   ,  0.25 ,  0.   ]],\n",
      "\n",
      "       [[ 0.   ,  0.125, -0.25 , ..., -0.25 ,  0.125,  0.   ],\n",
      "        [ 0.   , -0.125,  0.125, ...,  0.125,  0.125, -0.25 ],\n",
      "        [-0.125,  0.   ,  0.   , ...,  0.125,  0.   ,  0.   ],\n",
      "        ...,\n",
      "        [ 0.   ,  0.   ,  0.   , ..., -0.25 ,  0.125,  0.125],\n",
      "        [ 0.125,  0.   , -0.125, ...,  0.   ,  0.   ,  0.   ],\n",
      "        [-0.125,  0.   ,  0.   , ..., -0.125,  0.125,  0.   ]],\n",
      "\n",
      "       [[ 0.125,  0.125,  0.125, ..., -0.125,  0.125, -0.125],\n",
      "        [-0.25 , -0.125,  0.125, ..., -0.125,  0.125,  0.   ],\n",
      "        [ 0.125,  0.   , -0.125, ...,  0.125, -0.25 ,  0.125],\n",
      "        ...,\n",
      "        [ 0.   , -0.25 ,  0.   , ...,  0.125,  0.   ,  0.125],\n",
      "        [ 0.   ,  0.   , -0.125, ...,  0.125,  0.25 , -0.125],\n",
      "        [ 0.   , -0.125,  0.   , ...,  0.125,  0.125, -0.125]],\n",
      "\n",
      "       [[ 0.   , -0.125,  0.   , ...,  0.   , -0.125, -0.125],\n",
      "        [-0.25 , -0.25 , -0.25 , ...,  0.   ,  0.125, -0.125],\n",
      "        [ 0.   ,  0.125, -0.25 , ...,  0.   ,  0.   , -0.125],\n",
      "        ...,\n",
      "        [-0.125, -0.125,  0.   , ..., -0.125,  0.   , -0.25 ],\n",
      "        [-0.125,  0.   ,  0.25 , ..., -0.25 ,  0.125, -0.125],\n",
      "        [ 0.125, -0.125, -0.125, ...,  0.125, -0.125, -0.25 ]]],\n",
      "      dtype=float32), array([ 0.   , -0.125, -0.125,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   , -0.125,  0.   ,  0.   ,  0.   , -0.125,\n",
      "        0.   , -0.125,  0.   ,  0.   ,  0.   ,  0.   , -0.125,  0.   ,\n",
      "       -0.125,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "       -0.125,  0.   ,  0.   , -0.125,  0.   ,  0.   , -0.125,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   , -0.125,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   , -0.125,  0.   ,  0.   , -0.125,  0.   , -0.125,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   , -0.125,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   , -0.125,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   , -0.125,  0.   , -0.125,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   , -0.125,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   , -0.125,  0.   ,  0.   ,  0.   , -0.125],\n",
      "      dtype=float32), array([[[ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   , -0.125,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        ...,\n",
      "        [ 0.   ,  0.   ,  0.   , ..., -0.125,  0.125,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   , -0.125],\n",
      "        [ 0.   , -0.125,  0.   , ...,  0.   ,  0.   ,  0.   ]],\n",
      "\n",
      "       [[ 0.   ,  0.   ,  0.   , ..., -0.125,  0.   , -0.125],\n",
      "        [ 0.   , -0.125,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [-0.125,  0.   ,  0.   , ..., -0.125,  0.   , -0.125],\n",
      "        ...,\n",
      "        [ 0.125,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ..., -0.125,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   , -0.125, ...,  0.   ,  0.   ,  0.   ]],\n",
      "\n",
      "       [[ 0.125,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.125,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        ...,\n",
      "        [ 0.125,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ..., -0.125,  0.   ,  0.   ],\n",
      "        [-0.125,  0.   ,  0.   , ...,  0.   ,  0.125,  0.   ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.125,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        ...,\n",
      "        [ 0.125,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.125,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ]],\n",
      "\n",
      "       [[ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.125,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   , -0.125,  0.   ],\n",
      "        ...,\n",
      "        [ 0.125,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   , -0.125],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ]],\n",
      "\n",
      "       [[ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        ...,\n",
      "        [ 0.125,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   , -0.125,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   , -0.125,  0.   ]]],\n",
      "      dtype=float32), array([ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   , -0.125,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   , -0.125,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.125,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   , -0.125,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
      "      dtype=float32), array([[[ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.125],\n",
      "        [ 0.   , -0.125,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        ...,\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   , -0.125]],\n",
      "\n",
      "       [[ 0.125, -0.125,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        ...,\n",
      "        [ 0.   ,  0.125,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [-0.125,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ..., -0.125,  0.   ,  0.   ]],\n",
      "\n",
      "       [[ 0.   ,  0.   , -0.125, ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   , -0.125, ..., -0.125,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   , -0.125,  0.   ],\n",
      "        ...,\n",
      "        [-0.125,  0.   , -0.125, ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.125, ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ]],\n",
      "\n",
      "       [[ 0.   , -0.125, -0.125, ...,  0.   ,  0.   , -0.125],\n",
      "        [ 0.   ,  0.125, -0.125, ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   , -0.125,  0.   , ...,  0.   ,  0.   ,  0.125],\n",
      "        ...,\n",
      "        [ 0.   ,  0.125,  0.125, ...,  0.   ,  0.   , -0.125],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ]],\n",
      "\n",
      "       [[ 0.   ,  0.   ,  0.   , ..., -0.125,  0.   , -0.125],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ..., -0.125,  0.   ,  0.   ],\n",
      "        ...,\n",
      "        [-0.125,  0.125,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.125,  0.   ]]],\n",
      "      dtype=float32), array([ 0.   ,  0.   ,  0.   ,  0.   , -0.125,  0.   ,  0.   ,  0.   ,\n",
      "        0.   , -0.125,  0.   ,  0.   ,  0.   ,  0.125,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   , -0.125, -0.125,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   , -0.125,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.125, -0.125,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   , -0.125,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   , -0.125,  0.   ,  0.   ,  0.   , -0.125,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   , -0.125,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.125,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.125,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.125,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "       -0.125,  0.   ,  0.   ,  0.125,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   , -0.125,  0.   ,  0.   , -0.125,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   , -0.125,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   , -0.125,\n",
      "        0.   , -0.125,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   , -0.125,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   , -0.125,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
      "      dtype=float32), array([[[ 0.   ,  0.   ,  0.   , ...,  0.   , -0.125,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.125, ...,  0.   , -0.125,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        ...,\n",
      "        [ 0.   ,  0.   ,  0.125, ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [-0.125,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ]],\n",
      "\n",
      "       [[ 0.   ,  0.125,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        ...,\n",
      "        [-0.125,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   , -0.125,  0.   ]],\n",
      "\n",
      "       [[ 0.   ,  0.   , -0.125, ...,  0.   ,  0.   , -0.125],\n",
      "        [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "        [-0.125,  0.   , -0.125, ...,  0.   ,  0.   ,  0.   ],\n",
      "        ...,\n",
      "        [-0.125,  0.   ,  0.125, ...,  0.   ,  0.   ,  0.   ],\n",
      "        [-0.125,  0.   ,  0.   , ...,  0.   , -0.125,  0.   ],\n",
      "        [-0.125,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.125]]],\n",
      "      dtype=float32), array([ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.125,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   , -0.125,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.125,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   , -0.125,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
      "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
      "      dtype=float32), array([[-0.125,  0.   , -0.125, ...,  0.   ,  0.   ,  0.   ],\n",
      "       [ 0.   ,  0.125,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "       [ 0.125,  0.   ,  0.   , ...,  0.   ,  0.   , -0.125],\n",
      "       ...,\n",
      "       [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
      "       [ 0.   , -0.125,  0.125, ...,  0.   ,  0.125,  0.   ],\n",
      "       [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ]],\n",
      "      dtype=float32), array([0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.125, 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
      "      dtype=float32), array([[-0.125,  0.   ,  0.   , ...,  0.   , -0.125, -0.125],\n",
      "       [-0.25 , -0.25 ,  0.   , ..., -0.125, -0.25 ,  0.   ],\n",
      "       [ 0.   , -0.25 , -0.125, ...,  0.125,  0.   , -0.125],\n",
      "       ...,\n",
      "       [ 0.   ,  0.125, -0.125, ..., -0.125, -0.125, -0.125],\n",
      "       [ 0.   ,  0.   ,  0.   , ...,  0.   , -0.125,  0.   ],\n",
      "       [-0.125, -0.25 ,  0.   , ..., -0.25 , -0.25 , -0.375]],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "output_names = []\n",
    "\n",
    "for layer in model_m.layers:\n",
    "    if layer.__class__.__name__ in [\"QActivation\", \"Activation\",\n",
    "                                  \"QDense\", \"QConv1D\"]:\n",
    "        output_names.append(layer.name)\n",
    "        outputs.append(layer.output)\n",
    "\n",
    "all_weights = []\n",
    "model_save_quantized_weights(model_m)\n",
    "\n",
    "for layer in model_m.layers:\n",
    "      for w, weights in enumerate(layer.get_weights()):\n",
    "            print(layer.name, w)\n",
    "            all_weights.append(weights.flatten())\n",
    "\n",
    "all_weights = np.concatenate(all_weights).astype(np.float32)\n",
    "print(all_weights.size)\n",
    "    \n",
    "for layer in model_m.layers:\n",
    "      for w, weight in enumerate(layer.get_weights()):\n",
    "            print(layer.name, w, weight.shape)\n",
    "\n",
    "print(model_m.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.9112147e-03, 4.2889165e-05, 9.7205702e-06, ..., 1.2877663e-05,\n",
       "        2.6257117e-08, 2.3771251e-07],\n",
       "       [2.1851793e-07, 7.5676712e-07, 9.9953985e-01, ..., 4.8582356e-06,\n",
       "        4.9525767e-08, 1.1097256e-06],\n",
       "       [1.6722836e-08, 2.3301272e-10, 1.8261869e-07, ..., 5.7342833e-09,\n",
       "        1.3514125e-09, 9.9975950e-01],\n",
       "       ...,\n",
       "       [3.3212153e-05, 3.6973017e-06, 8.5964839e-06, ..., 2.5610459e-06,\n",
       "        7.6896549e-07, 2.5556673e-07],\n",
       "       [6.5402469e-06, 1.1365245e-06, 3.4196473e-06, ..., 4.7748978e-07,\n",
       "        4.8297402e-09, 6.3124261e-08],\n",
       "       [5.8626806e-06, 9.7975214e-07, 3.2124840e-06, ..., 4.7377722e-07,\n",
       "        5.3880025e-09, 6.2633468e-08]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predictions = model_all.predict(X_test)\n",
    "predictions = model_m.predict(X_test)\n",
    "display(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

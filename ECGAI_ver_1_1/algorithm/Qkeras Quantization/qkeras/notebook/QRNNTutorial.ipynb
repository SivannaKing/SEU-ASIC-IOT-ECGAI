{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Copyright 2020 Google LLC\n",
    "#\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow.compat.v2 as tf\n",
    "tf.enable_v2_behavior()\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, SimpleRNN, GRU, LSTM, Bidirectional\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "from qkeras.autoqkeras import *\n",
    "from qkeras import *\n",
    "\n",
    "print(\"using tensorflow\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices()\n",
    "for d in physical_devices:\n",
    "  print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  device_name = os.environ['COLAB_TPU_ADDR']\n",
    "  TPU_ADDRESS = 'grpc://' + device_name\n",
    "  print('Found TPU at: {}'.format(TPU_ADDRESS))\n",
    "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
    "  tf.config.experimental_connect_to_cluster(resolver)\n",
    "  # This is the TPU initialization code that has to be at the beginning.\n",
    "  tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "  print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
    "  strategy = tf.distribute.experimental.TPUStrategy(resolver)  \n",
    "except KeyError:\n",
    "  print('TPU not found')\n",
    "  strategy = tf.distribute.get_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "tf.random.set_seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "# cut texts after this number of words\n",
    "# (among top max_features most common words)\n",
    "maxlen = 100\n",
    "BATCH_SIZE = 1000\n",
    "SHUFFLE_BUFFER_SIZE = 25000\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE).shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using QKeras\n",
    "\n",
    "__QKeras__ works by tagging all variables and weights/bias created by Keras as well as output of arithmetic layers by quantized functions. Quantized functions can be instantiated directly in __`QSimpleRNN`__/__`QLSTM`__/__`QGRU`__/__`QBidirectional`__/__`QDense`__/__`QConv2D`__/__`QSeparableConv2D`__ functions, and they can be passed to __`QActivation`__, which act as a merged quantization and activation function.\n",
    "\n",
    "In order to successfully quantize a model, users need to replace layers that create variables (trainable or not) (`LSTM`, `Conv2D`, etc) by their equivalent ones in __QKeras__ (__`QLSTM`__/__`QDense`__, etc), and any layers that perform math operations need to be quantized afterwards.\n",
    "\n",
    "Quantized values are clipped between their maximum and minimum quantized representation (which may be different than $[-1.0, 1.0]$), although for `po2` type of quantizers, we still recommend the users to specify the parameter for `max_value`.\n",
    "\n",
    "An example of a very simple recurrent network is given below in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 64\n",
    "embedding_dim = 64\n",
    "loss = 'binary_crossentropy'\n",
    "\n",
    "def create_model(batch_size=None):\n",
    "  x = x_in = Input(shape=(maxlen,), batch_size=batch_size, dtype=tf.int32)\n",
    "  x = Embedding(input_dim=max_features, output_dim=embedding_dim)(x)\n",
    "  x = Activation('linear', name='embedding_act')(x)\n",
    "  x = Bidirectional(LSTM(units))(x)\n",
    "  x = Dense(1)(x)\n",
    "  x = Activation('sigmoid')(x)\n",
    "  model = tf.keras.Model(inputs=[x_in], outputs=[x])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "with strategy.scope():\n",
    "  model = create_model(BATCH_SIZE)\n",
    "  custom_objects = {}\n",
    "  model.compile(\n",
    "      optimizer=Adam(learning_rate=0.01),\n",
    "      loss=loss,\n",
    "      metrics=['acc'])\n",
    "\n",
    "model.summary()\n",
    "print('Train...')\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=10,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=test_dataset,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing with quantized layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_qmodel(batch_size=None):\n",
    "  x = x_in = Input(shape=(maxlen,), batch_size=batch_size, dtype=tf.int32)\n",
    "  x = Embedding(input_dim=max_features, output_dim=embedding_dim)(x)\n",
    "  x = QActivation('binary', name='embedding_act')(x)\n",
    "  x = QLSTM(\n",
    "    units,\n",
    "    activation='quantized_tanh(4)',\n",
    "    recurrent_activation='quantized_relu(4,0,1)',\n",
    "    kernel_quantizer='stochastic_ternary(\"auto\")',\n",
    "    recurrent_quantizer='quantized_bits(2,1,1,alpha=1.0)',\n",
    "    bias_quantizer='quantized_bits(4,0,1)')(x)\n",
    "  x = QDense(\n",
    "    1, \n",
    "    kernel_quantizer=\"quantized_bits(4,0,1)\",\n",
    "    bias_quantizer='quantized_bits(4,0,1)')(x)\n",
    "  x = QActivation('sigmoid')(x)\n",
    "  model = tf.keras.Model(inputs=[x_in], outputs=[x])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "with strategy.scope():\n",
    "  qmodel = create_qmodel(BATCH_SIZE)\n",
    "  custom_objects = {}\n",
    "  qmodel.compile(\n",
    "      optimizer=Adam(learning_rate=0.01),\n",
    "      loss=loss,\n",
    "      metrics=['acc'])\n",
    "\n",
    "qmodel.summary()\n",
    "print('Train...')\n",
    "qmodel.fit(train_dataset,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=10,\n",
    "          verbose=2,\n",
    "          validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting a Model Automatically\n",
    "\n",
    "In addition to the drop-in replacement of Keras functions, we have written the following function to assist anyone who wants to quantize a network.\n",
    "\n",
    "__`model_quantize(model, quantizer_config, activation_bits, custom_objects=None, transfer_weights=False)`__\n",
    "\n",
    "This function converts an non-quantized model (such as the one from `model` in the previous example) into a quantized version, by applying a configuration specified by the dictionary `quantizer_config`, and `activation_bits` specified for unamed activation functions, with this parameter probably being removed in future versions.\n",
    "\n",
    "The parameter `custom_objects` specifies object dictionary unknown to Keras, required when you copy a model with lambda layers, or customized layer functions, for example, and if `transfer_weights` is `True`, the returned model will have as initial weights the weights from the original model, instead of using random initial weights.\n",
    "\n",
    "The dictionary specified in `quantizer_config` can be indexed by a layer name or layer class name. In the example below, conv2d_1 corresponds to the first convolutional layer of the example, while  QConv2D corresponds to the default behavior of two dimensional convolutional layers. The reader should note that right now we recommend using __`QActivation`__ with a dictionary to avoid the conversion of activations such as `softmax` and `linear`.  In addition, although we could use `activation` field in the layers, we do not recommend that. \n",
    "\n",
    "`{\n",
    "  \"conv2d_1\": {\n",
    "      \"kernel_quantizer\": \"stochastic_ternary\",\n",
    "      \"bias_quantizer\": \"quantized_po2(4)\"\n",
    "  },\n",
    "  \"QConv2D\": {\n",
    "      \"kernel_quantizer\": \"stochastic_ternary\",\n",
    "      \"bias_quantizer\": \"quantized_po2(4)\"\n",
    "  },\n",
    "  \"QDense\": {\n",
    "      \"kernel_quantizer\": \"quantized_bits(3,0,1)\",\n",
    "      \"bias_quantizer\": \"quantized_bits(3)\"\n",
    "  },\n",
    "  \"act_1\": \"quantized_relu(2)\",\n",
    "  \"QActivation\": { \"relu\": \"quantized_relu(2)\" }\n",
    "}`\n",
    "\n",
    "In the following example, we will quantize the model using a different strategy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bits = 4\n",
    "quantizer_config = {\n",
    "  \"bidirectional\": {\n",
    "      'activation' : f\"quantized_tanh({bits})\",\n",
    "      'recurrent_activation' : f\"quantized_relu(4,0,1)\",\n",
    "      'kernel_quantizer' : f\"quantized_bits({bits}, alpha='auto')\",\n",
    "      'recurrent_quantizer' : f\"quantized_bits({bits}, alpha='auto')\",\n",
    "      'bias_quantizer' : f\"quantized_bits({bits}, alpha='auto')\",\n",
    "  },\n",
    "  \"dense\": {\n",
    "      'kernel_quantizer' : f\"quantized_bits({bits}), alpha='auto'\",\n",
    "      'bias_quantizer' : f\"quantized_bits({bits}), alpha='auto'\"\n",
    "  },\n",
    "  \"embedding_act\": f\"quantized_bits({bits}), alpha='auto'\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "with strategy.scope():\n",
    "  model = create_model(BATCH_SIZE)\n",
    "  custom_objects = {}\n",
    "  \n",
    "  qmodel = model_quantize(model, quantizer_config, bits, custom_objects)\n",
    "  qmodel.compile(\n",
    "      optimizer=Adam(learning_rate=0.01),\n",
    "      loss=loss,\n",
    "      metrics=['acc'])\n",
    "  \n",
    "qmodel.summary()\n",
    "print('Train...')\n",
    "qmodel.fit(train_dataset,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=10,\n",
    "          verbose=2,\n",
    "          validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantizing a Model With `AutoQKeras`\n",
    "\n",
    "To quantize this model with `AutoQKeras`, we need to define the quantization for kernels, biases and activations; forgiving factors and quantization strategy.\n",
    "\n",
    "Below we define which quantizers are allowed for kernel, bias, activations and linear. Linear is a proxy that we use to capture `Activation(\"linear\")` to apply quantization without applying a non-linear operation.  In some networks, we found that this trick may be necessary to better represent the quantization space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "with strategy.scope():\n",
    "  model = create_model(BATCH_SIZE)\n",
    "  custom_objects = {}\n",
    "  model.compile(\n",
    "      optimizer=Adam(learning_rate=0.01),\n",
    "      loss=loss,\n",
    "      metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = {\n",
    "        \"kernel\": {\n",
    "                \"stochastic_binary\": 1,\n",
    "                \"stochastic_ternary\": 2,\n",
    "                \"quantized_bits(4,0,1,alpha=1.0)\": 4,\n",
    "                \"quantized_po2(4,1)\": 4\n",
    "        },\n",
    "        \"recurrent_kernel\": {\n",
    "                \"stochastic_binary\": 1,\n",
    "                \"stochastic_ternary\": 2,\n",
    "                \"quantized_bits(4,0,1,alpha=1.0)\": 4,\n",
    "                \"quantized_po2(4,1)\": 4\n",
    "          \n",
    "        },\n",
    "        \"recurrent_activation\": {\n",
    "                \"quantized_relu(4,0,1)\": 4          \n",
    "        },\n",
    "        \"bias\": {\n",
    "                \"quantized_bits(4,0,1)\": 4,\n",
    "                \"quantized_po2(4,1)\": 4\n",
    "        },\n",
    "        \"activation\" : {\n",
    "            \"stochastic_ternary('auto')\": 2,\n",
    "            \"quantized_tanh(4)\" : 4, \n",
    "            \"quantized_relu_po2(4,1)\": 4,\n",
    "            \"quantized_relu(4,2)\": 4,\n",
    "        },\n",
    "        \"linear\": { \n",
    "                \"stochastic_ternary('auto')\" : 2,\n",
    "                \"quantized_tanh(4)\" : 4, \n",
    "                \"quantized_relu_po2(4,1)\": 4,\n",
    "                \"quantized_relu(3,1)\": 3,\n",
    "                \"quantized_relu(4,2)\": 4,\n",
    "        }\n",
    "}\n",
    "\n",
    "limit = {\n",
    "    \"Dense\": [4],\n",
    "    \"Bidirectional\": [4],\n",
    "    \"Activation\": [4],\n",
    "    \"default\" : [4]*4\n",
    "}\n",
    "\n",
    "goal = {\n",
    "    \"type\": \"bits\",\n",
    "    \"params\": {\n",
    "        \"delta_p\": 8.0,\n",
    "        \"delta_n\": 8.0,\n",
    "        \"rate\": 2.0,\n",
    "        \"stress\": 1.0,\n",
    "        \"input_bits\": 4,\n",
    "        \"output_bits\": 4,\n",
    "        \"ref_bits\": 4,\n",
    "        \"config\": {\n",
    "            \"default\": [\"parameters\", \"activations\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "run_config = {\n",
    "  \"output_dir\": tempfile.mkdtemp(),\n",
    "  \"goal\": goal,\n",
    "  \"quantization_config\": quantization_config,\n",
    "  \"learning_rate_optimizer\": False,\n",
    "  \"transfer_weights\": False,\n",
    "  \"mode\": \"random\",\n",
    "  \"seed\": 42,\n",
    "  \"limit\": limit,\n",
    "  \"tune_filters\": \"layer\",\n",
    "  \"tune_filters_exceptions\": \"^dense\",\n",
    "  \"distribution_strategy\": strategy,\n",
    "\n",
    "  \"layer_indexes\": range(2, len(model.layers) - 1),\n",
    "  \"max_trials\": 1000\n",
    "}\n",
    "\n",
    "print(\"quantizing layers:\", [model.layers[i].name for i in run_config[\"layer_indexes\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "autoqk = AutoQKeras(model, metrics=[\"acc\"], custom_objects={}, **run_config)\n",
    "autoqk.fit(\n",
    "  train_dataset, \n",
    "  validation_data=test_dataset, \n",
    "  batch_size=BATCH_SIZE, \n",
    "  epochs=10,\n",
    "  verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "qmodel = autoqk.get_best_model()\n",
    "qmodel.save_weights(\"qmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_qmodel_summary(qmodel)\n",
    "print(get_quantization_dictionary(qmodel))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
